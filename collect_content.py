# -*- coding: utf-8 -*-
"""
AI+é¡¹ç›®ç®¡ç†ä¿¡æ¯é¢æ¿ - å†…å®¹æœç´¢å’ŒæŠ“å–
ä½¿ç”¨é˜¿é‡Œäº‘é€šä¹‰åƒé—®API
"""

import json
import time
from datetime import datetime
from openai import OpenAI
import config

class AINewsCollector:
    """AIæ–°é—»å’Œæ¡ˆä¾‹æ”¶é›†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–APIå®¢æˆ·ç«¯"""
        if not config.check_config():
            raise ValueError("é…ç½®ä¸å®Œæ•´ï¼Œè¯·æ£€æŸ¥ QWEN_API_KEY")
        
        # ä½¿ç”¨ OpenAI å…¼å®¹æ¥å£
        self.client = OpenAI(
            api_key=config.QWEN_API_KEY,
            base_url=config.QWEN_API_BASE
        )
        self.model = config.QWEN_MODEL
    
    def search_and_summarize(self, query, content_type='news', count=10):
        """
        æœç´¢å¹¶æ€»ç»“å†…å®¹
        """
        try:
            # æ„å»ºæç¤ºè¯
            if content_type == 'news':
                prompt = f"""è¯·æ€»ç»“å…³äº"{query}"çš„æœ€æ–°AIé¢†åŸŸåŠ¨æ€ã€‚

è¦æ±‚ï¼š
1. æ‰¾åˆ°{count}æ¡æœ€é‡è¦ã€æœ€æ–°çš„AIé¢†åŸŸè¿›å±•
2. æ¯æ¡æ–°é—»åŒ…å«ï¼šæ ‡é¢˜ã€æ‘˜è¦ï¼ˆ2-3å¥è¯ï¼‰ã€é‡è¦æ€§çº§åˆ«ï¼ˆhigh/mediumï¼‰ã€ç›¸å…³æ ‡ç­¾
3. ä¼˜å…ˆé€‰æ‹©å¯¹é¡¹ç›®ç®¡ç†ã€ç”Ÿäº§åŠ›å·¥å…·æœ‰å½±å“çš„AIè¿›å±•
4. æŒ‰é‡è¦æ€§æ’åº

è¯·ä¸¥æ ¼ä»¥JSONæ ¼å¼è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
[
  {{
    "title": "æ–°é—»æ ‡é¢˜",
    "summary": "æ–°é—»æ‘˜è¦å†…å®¹",
    "priority": "high",
    "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2"],
    "date": "{datetime.now().strftime('%Yå¹´%mæœˆ')}"
  }}
]

åªè¿”å›JSONï¼Œä¸è¦åŒ…å«ä»»ä½•MarkDownä»£ç å—æ ‡è®°æˆ–å…¶ä»–æ–‡å­—ã€‚"""
            
            else:  # case
                prompt = f"""è¯·åˆ—ä¸¾å…³äº"{query}"çš„å®é™…åº”ç”¨æ¡ˆä¾‹ã€‚

è¦æ±‚ï¼š
1. æ‰¾åˆ°{count}ä¸ªAIåœ¨é¡¹ç›®ç®¡ç†ä¸­çš„çœŸå®åº”ç”¨æ¡ˆä¾‹
2. æ¯ä¸ªæ¡ˆä¾‹åŒ…å«ï¼šæ ‡é¢˜ã€å…¬å¸/è¡Œä¸šã€æè¿°ã€é‡åŒ–æ•ˆæœ
3. ä¼˜å…ˆé€‰æ‹©æœ‰å…·ä½“æ•°æ®æ”¯æ’‘çš„æ¡ˆä¾‹

è¯·ä¸¥æ ¼ä»¥JSONæ ¼å¼è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
[
  {{
    "title": "æ¡ˆä¾‹æ ‡é¢˜",
    "company": "å…¬å¸åç§°",
    "industry": "è¡Œä¸šç±»åˆ«",
    "description": "è¯¦ç»†æè¿°AIå¦‚ä½•åº”ç”¨",
    "impact": ["æ•ˆæœ1", "æ•ˆæœ2"]
  }}
]

åªè¿”å›JSONï¼Œä¸è¦åŒ…å«ä»»ä½•MarkDownä»£ç å—æ ‡è®°æˆ–å…¶ä»–æ–‡å­—ã€‚"""
            
            # è°ƒç”¨é€šä¹‰åƒé—®API
            # æ³¨æ„ï¼šæ­¤å¤„åˆ é™¤äº†ä¼šå¯¼è‡´æŠ¥é”™çš„ enable_search=True å‚æ•°
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        'role': 'system',
                        'content': 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIä¿¡æ¯åˆ†æå¸ˆï¼Œä¸“æ³¨äºAI+é¡¹ç›®ç®¡ç†é¢†åŸŸã€‚è¯·ç›´æ¥è¿”å›JSONæ ¼å¼çš„æ•°æ®ã€‚'
                    },
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                temperature=0.7
            )
            
            # è§£æå“åº”
            content = response.choices[0].message.content.strip()
            
            # æ¸…ç†å¯èƒ½çš„ Markdown æ ‡è®°
            if '```json' in content:
                content = content.split('```json')[1].split('```')[0].strip()
            elif '```' in content:
                content = content.split('```')[1].split('```')[0].strip()
            
            # è§£æJSON
            results = json.loads(content)
            
            print(f"âœ… æˆåŠŸè·å– {len(results)} æ¡{content_type}å†…å®¹")
            return results
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æé”™è¯¯: {e}")
            return []
        except Exception as e:
            print(f"âŒ è¿è¡Œå¤±è´¥: {e}")
            return []
    
    def collect_ai_news(self):
        """æ”¶é›†AIåŠ¨æ€æ–°é—»"""
        print("\nğŸ“° å¼€å§‹æ”¶é›†AIåŠ¨æ€æ–°é—»...")
        all_news = []
        
        # é»˜è®¤ä»é…ç½®ä¸­è¯»å–å…³é”®è¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨å¤‡ç”¨
        keywords = getattr(config, 'SEARCH_KEYWORDS', {}).get('ai_news', ["AI latest developments", "Project Management AI"])
        
        for keyword in keywords[:2]:
            print(f"  ğŸ” å¤„ç†å…³é”®è¯: {keyword}")
            news = self.search_and_summarize(query=keyword, content_type='news', count=5)
            all_news.extend(news)
            time.sleep(1)
        
        return self._deduplicate(all_news, 'title')[:10]
    
    def collect_pm_cases(self):
        """æ”¶é›†é¡¹ç›®ç®¡ç†æ¡ˆä¾‹"""
        print("\nğŸ’¼ å¼€å§‹æ”¶é›†é¡¹ç›®ç®¡ç†æ¡ˆä¾‹...")
        all_cases = []
        
        keywords = getattr(config, 'SEARCH_KEYWORDS', {}).get('pm_cases', ["AI project management tools", "AI case study"])
        
        for keyword in keywords[:2]:
            print(f"  ğŸ” å¤„ç†å…³é”®è¯: {keyword}")
            cases = self.search_and_summarize(query=keyword, content_type='case', count=5)
            all_cases.extend(cases)
            time.sleep(1)
        
        return self._deduplicate(all_cases, 'title')[:6]
    
    def _deduplicate(self, items, key):
        """æ ¹æ®æŒ‡å®šé”®å»é‡"""
        seen = set()
        unique = []
        for item in items:
            val = item.get(key)
            if val not in seen:
                seen.add(val)
                unique.append(item)
        return unique

    def save_data(self, news, cases, filename='data.json'):
        """ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶"""
        data = {
            'update_time': datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M'),
            'news': news,
            'cases': cases,
            'stats': {
                'news_count': len(news),
                'case_count': len(cases)
            }
        }
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ° {filename}")
        return data

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ AI+é¡¹ç›®ç®¡ç†ä¿¡æ¯é¢æ¿ - å†…å®¹æ›´æ–°")
    print("=" * 60)
    
    collector = AINewsCollector()
    news = collector.collect_ai_news()
    cases = collector.collect_pm_cases()
    collector.save_data(news, cases)
    
    print("\nâœ… æ›´æ–°å®Œæˆï¼")
    print(f"ğŸ“Š åŠ¨æ€: {len(news)} | æ¡ˆä¾‹: {len(cases)}")
    print("=" * 60)

if __name__ == '__main__':
    main()
