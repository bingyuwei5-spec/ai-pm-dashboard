# -*- coding: utf-8 -*-
"""
AI+é¡¹ç›®ç®¡ç†ä¿¡æ¯é¢æ¿ - å†…å®¹æœç´¢å’ŒæŠ“å–
ä½¿ç”¨é˜¿é‡Œäº‘é€šä¹‰åƒé—®APIï¼ˆå¯ç”¨è”ç½‘æœç´¢ï¼‰
"""

import json
import time
import re
from datetime import datetime
from openai import OpenAI
import config

class AINewsCollector:
    """AIæ–°é—»å’Œæ¡ˆä¾‹æ”¶é›†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–APIå®¢æˆ·ç«¯"""
        if not config.QWEN_API_KEY:
            raise ValueError("æœªè®¾ç½® QWEN_API_KEYï¼Œè¯·æ£€æŸ¥é…ç½®")
        
        self.client = OpenAI(
            api_key=config.QWEN_API_KEY,
            base_url=config.QWEN_API_BASE
        )
        self.model = config.QWEN_MODEL
        print(f"âœ… ä½¿ç”¨æ¨¡å‹: {self.model}")
    
    def search_and_summarize(self, query, content_type='news', count=5):
        """
        æœç´¢å¹¶æ€»ç»“å†…å®¹ï¼ˆå¯ç”¨è”ç½‘æœç´¢ï¼‰
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            content_type: 'news' æˆ– 'case'
            count: éœ€è¦çš„æ¡æ•°
        
        Returns:
            list: æ€»ç»“åçš„å†…å®¹åˆ—è¡¨
        """
        try:
            # æ„å»ºæç¤ºè¯
            if content_type == 'news':
                prompt = f"""è¯·æœç´¢å…³äº"{query}"çš„æœ€æ–°AIåŠ¨æ€æ–°é—»ï¼ˆ2025-2026å¹´ï¼‰ã€‚

è¦æ±‚ï¼š
1. å¿…é¡»æœç´¢äº’è”ç½‘è·å–æœ€æ–°ä¿¡æ¯
2. æ‰¾åˆ°{count}æ¡2025å¹´æˆ–2026å¹´çš„é‡è¦AIæ–°é—»
3. æ¯æ¡æ–°é—»å¿…é¡»åŒ…å«ï¼šæ ‡é¢˜ã€æ‘˜è¦ï¼ˆ2-3å¥è¯ï¼‰ã€é‡è¦æ€§çº§åˆ«ï¼ˆhigh/mediumï¼‰ã€ç›¸å…³æ ‡ç­¾ã€æ—¥æœŸ
4. ä¼˜å…ˆé€‰æ‹©å¯¹é¡¹ç›®ç®¡ç†æœ‰å½±å“çš„AIè¿›å±•
5. å¿…é¡»æ˜¯çœŸå®å­˜åœ¨çš„æ–°é—»ï¼Œä¸è¦ç¼–é€ 

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–æ–‡å­—ï¼š
[
  {{
    "title": "æ–°é—»æ ‡é¢˜",
    "summary": "æ–°é—»æ‘˜è¦ï¼Œè¯´æ˜è¦ç‚¹å’Œå½±å“",
    "priority": "high",
    "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2"],
    "date": "2026å¹´2æœˆ"
  }}
]"""
            
            else:  # case
                prompt = f"""è¯·æœç´¢å…³äº"{query}"çš„çœŸå®åº”ç”¨æ¡ˆä¾‹ã€‚

è¦æ±‚ï¼š
1. å¿…é¡»æœç´¢äº’è”ç½‘è·å–çœŸå®æ¡ˆä¾‹
2. æ‰¾åˆ°{count}ä¸ªAIåœ¨é¡¹ç›®ç®¡ç†ä¸­çš„å®é™…åº”ç”¨æ¡ˆä¾‹
3. æ¯ä¸ªæ¡ˆä¾‹å¿…é¡»åŒ…å«ï¼šæ ‡é¢˜ã€å…¬å¸ã€è¡Œä¸šã€æè¿°ã€é‡åŒ–æ•ˆæœ
4. å¿…é¡»æ˜¯çœŸå®çš„æ¡ˆä¾‹ï¼ŒåŒ…å«å…·ä½“å…¬å¸åç§°
5. ä¼˜å…ˆé€‰æ‹©æœ‰æ˜ç¡®æ•°æ®æ”¯æŒçš„æ¡ˆä¾‹

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–æ–‡å­—ï¼š
[
  {{
    "title": "æ¡ˆä¾‹æ ‡é¢˜",
    "company": "å…¬å¸åç§°",
    "industry": "è¡Œä¸š",
    "description": "æ¡ˆä¾‹æè¿°ï¼Œè¯´æ˜å¦‚ä½•ä½¿ç”¨AI",
    "impact": ["æ•ˆæœ1", "æ•ˆæœ2", "æ•ˆæœ3"]
  }}
]"""
            
            print(f"  ğŸ” æœç´¢: {query}")
            
            # è°ƒç”¨é€šä¹‰åƒé—®API - å…³é”®ï¼šå¯ç”¨è”ç½‘æœç´¢
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        'role': 'system',
                        'content': 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIä¿¡æ¯åˆ†æå¸ˆã€‚ä½ å¿…é¡»ä½¿ç”¨è”ç½‘æœç´¢åŠŸèƒ½è·å–æœ€æ–°çš„çœŸå®ä¿¡æ¯ï¼Œç„¶åç”¨ä¸­æ–‡æ€»ç»“ã€‚ä¸è¦ç¼–é€ å†…å®¹ã€‚'
                    },
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                temperature=0.5,
                # ğŸ”¥ å…³é”®è®¾ç½®ï¼šå¯ç”¨è”ç½‘æœç´¢
                extra_body={
                    "enable_search": True  # é˜¿é‡Œäº‘é€šä¹‰åƒé—®çš„è”ç½‘æœç´¢å‚æ•°
                }
            )
            
            # è§£æå“åº”
            content = response.choices[0].message.content.strip()
            
            # æå–JSONï¼ˆå»é™¤å¯èƒ½çš„markdownæ ‡è®°ï¼‰
            content = self._extract_json(content)
            
            # è§£æJSON
            results = json.loads(content)
            
            # éªŒè¯æ•°æ®å®Œæ•´æ€§
            results = self._validate_data(results, content_type)
            
            print(f"  âœ… æˆåŠŸè·å– {len(results)} æ¡å†…å®¹")
            return results
            
        except json.JSONDecodeError as e:
            print(f"  âŒ JSONè§£æé”™è¯¯: {e}")
            print(f"  åŸå§‹å†…å®¹: {content[:300]}...")
            return []
        except Exception as e:
            print(f"  âŒ æœç´¢å¤±è´¥: {e}")
            return []
    
    def _extract_json(self, content):
        """æå–JSONå†…å®¹"""
        # å»é™¤markdownä»£ç å—æ ‡è®°
        if '```json' in content:
            content = content.split('```json')[1].split('```')[0].strip()
        elif '```' in content:
            content = content.split('```')[1].split('```')[0].strip()
        
        # ä½¿ç”¨æ­£åˆ™æå–JSONæ•°ç»„
        match = re.search(r'\[.*\]', content, re.DOTALL)
        if match:
            return match.group()
        
        return content
    
    def _validate_data(self, results, content_type):
        """éªŒè¯å’Œä¿®å¤æ•°æ®"""
        if not isinstance(results, list):
            return []
        
        valid_results = []
        for item in results:
            if content_type == 'news':
                # éªŒè¯æ–°é—»å¿…éœ€å­—æ®µ
                if all(key in item for key in ['title', 'summary', 'priority', 'tags', 'date']):
                    # ç¡®ä¿tagsæ˜¯æ•°ç»„
                    if isinstance(item['tags'], str):
                        item['tags'] = [item['tags']]
                    valid_results.append(item)
            else:
                # éªŒè¯æ¡ˆä¾‹å¿…éœ€å­—æ®µ
                if all(key in item for key in ['title', 'company', 'industry', 'description', 'impact']):
                    # ç¡®ä¿impactæ˜¯æ•°ç»„
                    if isinstance(item['impact'], str):
                        item['impact'] = [item['impact']]
                    valid_results.append(item)
        
        return valid_results
    
    def collect_ai_news(self):
        """æ”¶é›†AIåŠ¨æ€æ–°é—»"""
        print("\nğŸ“° å¼€å§‹æ”¶é›†AIåŠ¨æ€æ–°é—»...")
        all_news = []
        
        # ä½¿ç”¨æ›´ç²¾ç¡®çš„æœç´¢å…³é”®è¯
        keywords = [
            "AI latest news 2026",  # è‹±æ–‡æœç´¢é€šå¸¸æ›´å‡†ç¡®
            "artificial intelligence breakthroughs 2025 2026",
            "AIé¡¹ç›®ç®¡ç† 2026 æœ€æ–°",
        ]
        
        for keyword in keywords[:2]:  # ä½¿ç”¨å‰2ä¸ªå…³é”®è¯
            news = self.search_and_summarize(
                query=keyword,
                content_type='news',
                count=5
            )
            all_news.extend(news)
            time.sleep(2)  # é¿å…è¯·æ±‚è¿‡å¿«
        
        # å»é‡
        unique_news = self._deduplicate(all_news, 'title')
        return unique_news[:config.NEWS_COUNT]
    
    def collect_pm_cases(self):
        """æ”¶é›†é¡¹ç›®ç®¡ç†æ¡ˆä¾‹"""
        print("\nğŸ’¼ å¼€å§‹æ”¶é›†é¡¹ç›®ç®¡ç†æ¡ˆä¾‹...")
        all_cases = []
        
        keywords = [
            "AI project management case study 2025 2026",
            "ä¼ä¸šAIé¡¹ç›®ç®¡ç†å®è·µæ¡ˆä¾‹",
        ]
        
        for keyword in keywords[:2]:
            cases = self.search_and_summarize(
                query=keyword,
                content_type='case',
                count=5
            )
            all_cases.extend(cases)
            time.sleep(2)
        
        # å»é‡
        unique_cases = self._deduplicate(all_cases, 'title')
        return unique_cases[:config.CASE_COUNT]
    
    def _deduplicate(self, items, key):
        """æ ¹æ®æŒ‡å®šé”®å»é‡"""
        seen = set()
        unique = []
        for item in items:
            if item.get(key) not in seen:
                seen.add(item.get(key))
                unique.append(item)
        return unique
    
    def save_data(self, news, cases):
        """ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶"""
        data = {
            'update_time': datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M'),
            'news': news if news else [
                {
                    "title": "æ­£åœ¨è·å–æœ€æ–°æ•°æ®...",
                    "summary": "ç³»ç»Ÿæ­£åœ¨æœç´¢æœ€æ–°çš„AIåŠ¨æ€ï¼Œè¯·ç¨ååˆ·æ–°é¡µé¢",
                    "priority": "medium",
                    "tags": ["ç³»ç»Ÿæç¤º"],
                    "date": datetime.now().strftime('%Yå¹´%mæœˆ')
                }
            ],
            'cases': cases if cases else [
                {
                    "title": "æ­£åœ¨åŠ è½½æ¡ˆä¾‹...",
                    "company": "ç³»ç»Ÿ",
                    "industry": "æŠ€æœ¯",
                    "description": "æ­£åœ¨æœç´¢æœ€æ–°çš„AIé¡¹ç›®ç®¡ç†æ¡ˆä¾‹",
                    "impact": ["åŠ è½½ä¸­..."]
                }
            ],
            'stats': {
                'news_count': len(news) if news else 0,
                'case_count': len(cases) if cases else 0
            }
        }
        
        with open('data.json', 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ° data.json")
        return data

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ AI+é¡¹ç›®ç®¡ç†ä¿¡æ¯é¢æ¿ - å†…å®¹æ›´æ–°")
    print("=" * 60)
    
    try:
        # åˆå§‹åŒ–æ”¶é›†å™¨
        collector = AINewsCollector()
        
        # æ”¶é›†å†…å®¹
        news = collector.collect_ai_news()
        cases = collector.collect_pm_cases()
        
        # ä¿å­˜æ•°æ®
        data = collector.save_data(news, cases)
        
        print("\n" + "=" * 60)
        print(f"âœ… æ›´æ–°å®Œæˆï¼")
        print(f"ğŸ“Š AIåŠ¨æ€: {len(news)} æ¡")
        print(f"ğŸ’¡ å®è·µæ¡ˆä¾‹: {len(cases)} ä¸ª")
        print(f"â° æ›´æ–°æ—¶é—´: {data['update_time']}")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()
